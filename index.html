<html>
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<title>Zhiqin Chen</title>
		<link rel="shortcut icon" href="image/myico.png" />
	</head>
	<body bgcolor="#F0F0F0">
<div style="font-family:Arial; font-size:24; position:absolute; top:0.3%; left:10%; right:10%">
<table style="font-size:24;">
<tr>
	<td colspan="1" align="center" >
		<br>
		<a href="http://www.sfu.ca/~zhiqinc/jigsaw" style="text-decoration: none">
			<img src="image/me.png"  style="height: 436px; width: 337px;"  align="center"  />
		</a>
	</td>
	<td colspan="1" align="center">&nbsp&nbsp&nbsp&nbsp</td>
	<td colspan="3" valign="top" >
		
		<br>
			<h2> Zhiqin Chen </h2>
			<h4> Ph.D. Student </h4>
			<a href="https://gruvi.cs.sfu.ca/" style="text-decoration: none">GrUVi lab</a>, <a href="https://www.cs.sfu.ca/"  style="text-decoration: none">school of Computing Science</a>, <a href="https://www.sfu.ca/" style="text-decoration: none">Simon Fraser University</a>
			<br><br>
			zhiqinc at sfu dot ca
			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			<a href="https://scholar.google.com/citations?user=ytK2uIoAAAAJ&hl=en" style="text-decoration: none">Google Scholar</a>
			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			<a href="https://github.com/czq142857" style="text-decoration: none">GitHub</a>
			&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
			<a href="image/CV_czq.pdf" style="text-decoration: none">CV</a>
			<br><br>
			<small>
			I am an incoming research scientist at Adobe. I received my PhD and Master's degree from Simon Fraser University, supervised by <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Prof. Hao (Richard) Zhang</a>, and obtained my Bachelor's degree from Shanghai Jiao Tong University. I have won the best student paper award at CVPR 2020 and best paper award candidate at CVPR 2023. I was an NVIDIA graduate fellowship finalist and received Google PhD Fellowship in 2021. I have also interned at Adobe, NVIDIA, and Google in the past. My research interest is in computer graphics with a specialty in geometric modeling, machine learning, 3D reconstruction, and shape synthesis.
			</small>
	</td>
</tr>

<tr>
	<td>
		<br><br>
		<h2>Publications</h2>
	</td>
</tr>

<tr>
	<td>
		<h3>2023</h3>
	</td>
</tr>

<tr>
	<td colspan="1" valign="middle" >
		<a href="https://theses.lib.sfu.ca/file/thesis/7528" style="text-decoration: none">
			<img src="image/thesis23.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>Neural Mesh Reconstruction</strong>
	<br>
	<u>Zhiqin Chen</u>
	<br>
	PhD thesis, Simon Fraser University, 2023
	<br>
	[<a href="https://theses.lib.sfu.ca/file/thesis/7528" style="text-decoration: none">PDF</a>]
	<br>
	</td>
</tr>

<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/2303.02879" style="text-decoration: none">
			<img src="image/depth23.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>A Review of Deep Learning-Powered Mesh Reconstruction Methods</strong>
	<br>
	<u>Zhiqin Chen</u>
	<br>
	PhD depth report
	<br>
	[<a href="https://arxiv.org/abs/2303.02879" style="text-decoration: none">ArXiv</a>]
	<br>
	</td>
</tr>

<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/2208.00277" style="text-decoration: none">
			<img src="image/cvpr23_mobilenerf.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>MobileNeRF: Exploiting the Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile Architectures</strong>
	<br>
	<u>Zhiqin Chen</u>, <a href="https://www.cs.princeton.edu/~funk/" style="text-decoration: none">Thomas Funkhouser</a>, <a href="https://phogzone.com/" style="text-decoration: none">Peter Hedman</a>, and <a href="https://taiya.github.io/" style="text-decoration: none">Andrea Tagliasacchi</a>
	<br>
	Accepted to CVPR 2023
	<br>
	<strong style="color:red">CVPR 2023 Best Paper Award Candidate</strong>
	<br>
	[<a href="https://arxiv.org/abs/2208.00277" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/google-research/jax3d/tree/main/jax3d/projects/mobilenerf" style="text-decoration: none">GitHub</a>] [<a href="https://mobile-nerf.github.io/" style="text-decoration: none">Project page</a>] [<a href="https://youtu.be/C1rULzOcjuw" style="text-decoration: none">Video</a>]
	<br>
	</td>
</tr>

<tr>
	<td>
		<h3>2022</h3>
	</td>
</tr>

<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/2202.01999" style="text-decoration: none">
			<img src="image/sig22_NDC.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>Neural Dual Contouring</strong>
	<br>
	<u>Zhiqin Chen</u>, <a href="https://taiya.github.io/" style="text-decoration: none">Andrea Tagliasacchi</a>, <a href="https://www.cs.princeton.edu/~funk/" style="text-decoration: none">Thomas Funkhouser</a>, and <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>
	<br>
	Accepted to SIGGRAPH 2022 (journal)
	<br>
	[<a href="https://arxiv.org/abs/2202.01999" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/czq142857/NDC" style="text-decoration: none">GitHub</a>] [<a href="https://youtu.be/uQV9GqeKaQg" style="text-decoration: none">Video</a>]
	<br>
	</td>
</tr>

<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/2204.03105" style="text-decoration: none">
			<img src="image/cvpr22_auvnet.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>AUV-Net: Learning Aligned UV Maps for Texture Transfer and Synthesis</strong>
	<br>
	<u>Zhiqin Chen</u>, <a href="https://kangxue.org/" style="text-decoration: none">Kangxue Yin</a>, and <a href="https://www.cs.utoronto.ca/~fidler/" style="text-decoration: none">Sanja Fidler</a>
	<br>
	Accepted to CVPR 2022
	<br>
	[<a href="https://arxiv.org/abs/2204.03105" style="text-decoration: none">ArXiv</a>] [<a href="https://nv-tlabs.github.io/AUV-NET/" style="text-decoration: none">Project page</a>] [<a href="https://youtu.be/rsGsN96EUv8" style="text-decoration: none">Video</a>]
	<br>
	</td>
</tr>


<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/2104.05652" style="text-decoration: none">
			<img src="image/cvpr22_capri.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>CAPRI-Net: Learning Compact CAD Shapes with Adaptive Primitive Assembly</strong>
	<br>
	<a href="https://fenggenyu.github.io/" style="text-decoration: none">Fenggen Yu</a>, <u>Zhiqin Chen</u>, <a href="https://manyili12345.github.io/" style="text-decoration: none">Manyi Li</a>, Aditya Sanghi, Hooman Shayani, <a href="https://sites.google.com/site/alimahdaviamiri/" style="text-decoration: none">Ali Mahdavi-Amiri</a>, and <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>
	<br>
	Accepted to CVPR 2022
	<br>
	[<a href="https://arxiv.org/abs/2104.05652" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/FENGGENYU/CAPRI-Net" style="text-decoration: none">GitHub</a>] [<a href="https://fenggenyu.github.io/capri.html" style="text-decoration: none">Project page</a>] [<a href="https://youtu.be/6g7mxJuN_sc" style="text-decoration: none">Video</a>]
	<br>
	</td>
</tr>


<tr>
	<td>
	<br>
		<h3>2021</h3>
	</td>
</tr>


<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/2106.11272" style="text-decoration: none">
			<img src="image/siga21_NMC.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>Neural Marching Cubes</strong>
	<br>
	<u>Zhiqin Chen</u> and <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>
	<br>
	Accepted to SIGGRAPH Asia 2021 (journal)
	<br>
	[<a href="https://arxiv.org/abs/2106.11272" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/czq142857/NMC" style="text-decoration: none">GitHub</a>] [<a href="https://youtu.be/O7NFYN3YzDM" style="text-decoration: none">Video</a>]
	<br>
	</td>
</tr>


<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/2012.09159" style="text-decoration: none">
			<img src="image/cvpr21_decorgan.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>DECOR-GAN: 3D Shape Detailization by Conditional Refinement</strong>
	<br>
	<u>Zhiqin Chen</u>, <a href="http://www.vovakim.com/" style="text-decoration: none">Vladimir G. Kim</a>, <a href="https://techmatt.github.io/" style="text-decoration: none">Matthew Fisher</a>, <a href="https://noamaig.github.io/" style="text-decoration: none">Noam Aigerman</a>, <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>, and <a href="https://www.cse.iitb.ac.in/~sidch/" style="text-decoration: none">Siddhartha Chaudhuri</a>
	<br>
	Accepted to CVPR 2021 (oral)
	<br>
	[<a href="https://arxiv.org/abs/2012.09159" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/czq142857/DECOR-GAN" style="text-decoration: none">GitHub</a>] [<a href="https://youtu.be/5Fg3RF45mGg" style="text-decoration: none">Video</a>] [<a href="https://youtu.be/xIQ0aslpn8g" style="text-decoration: none">GUI demo</a>]
	<br>
	</td>
</tr>


<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/2106.14274" style="text-decoration: none">
			<img src="image/tpami21_bspnet.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>Learning Mesh Representations via Binary Space Partitioning Tree Networks</strong>
	<br>
	<u>Zhiqin Chen</u>, <a href="https://taiya.github.io/" style="text-decoration: none">Andrea Tagliasacchi</a>, and <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>
	<br>
	Accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)
	<br>
	[<a href="https://arxiv.org/abs/2106.14274" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/czq142857/BSP-NET-original" style="text-decoration: none">GitHub</a>]
	<br>
	</td>
</tr>


<tr>
	<td>
	<br>
		<h3>2020</h3>
	</td>
</tr>


<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/2008.01936" style="text-decoration: none">
			<img src="image/3dv20_coalesce.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>COALESCE: Component Assembly by Learning to Synthesize Connections</strong>
	<br>
	<a href="http://kangxue.org/" style="text-decoration: none">Kangxue Yin</a>, <u>Zhiqin Chen</u>, <a href="https://www.cse.iitb.ac.in/~sidch/" style="text-decoration: none">Siddhartha Chaudhuri</a>, <a href="https://techmatt.github.io/" style="text-decoration: none">Matthew Fisher</a>, <a href="http://www.vovakim.com/" style="text-decoration: none">Vladimir G. Kim</a>, and <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>
	<br>
	Accepted to 3DV 2020 (oral)
	<br>
	[<a href="https://arxiv.org/abs/2008.01936" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/kangxue/COALESCE" style="text-decoration: none">GitHub</a>] [<a href="https://kangxue.org/papers/COALESCE.mp4" style="text-decoration: none">Video</a>]
	<br>
	</td>
</tr>


<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/1911.06971" style="text-decoration: none">
			<img src="image/cvpr20_bspnet.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>BSP-Net: Generating Compact Meshes via Binary Space Partitioning</strong>
	<br>
	<u>Zhiqin Chen</u>, <a href="https://taiya.github.io/" style="text-decoration: none">Andrea Tagliasacchi</a>, and <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>
	<br>
	Accepted to CVPR 2020
	<br>
	<strong style="color:red">CVPR 2020 Best Student Paper Award</strong>
	<br>
	[<a href="https://arxiv.org/abs/1911.06971" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/czq142857/BSP-NET-original" style="text-decoration: none">GitHub</a>] [<a href="https://youtu.be/9-ixexpjN-8" style="text-decoration: none">Video</a>] [<a href="https://bsp-net.github.io" style="text-decoration: none">Project page</a>]
	<br>
	</td>
</tr>


<tr>
	<td>
	<br>
		<h3>2019</h3>
	</td>
</tr>


<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/1903.10170" style="text-decoration: none">
			<img src="image/siga19_logan.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>LOGAN: Unpaired Shape Transform in Latent Overcomplete Space</strong>
	<br>
	<a href="http://kangxue.org/" style="text-decoration: none">Kangxue Yin</a>, <u>Zhiqin Chen</u>, <a href="http://vcc.szu.edu.cn/~huihuang/" style="text-decoration: none">Hui Huang</a>, <a href="https://www.cs.tau.ac.il/~dcor/" style="text-decoration: none">Daniel Cohen-Or</a>, <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>
	<br>
	Accepted to SIGGRAPH Asia 2019
	<br>
	[<a href="https://arxiv.org/abs/1903.10170" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/kangxue/LOGAN" style="text-decoration: none">GitHub</a>]
	<br>
	</td>
</tr>


<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/1903.11228" style="text-decoration: none">
			<img src="image/iccv19_baenet.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>BAE-NET: Branched Autoencoder for Shape Co-Segmentation</strong>
	<br>
	<u>Zhiqin Chen</u>, <a href="http://kangxue.org/" style="text-decoration: none">Kangxue Yin</a>, <a href="https://techmatt.github.io/" style="text-decoration: none">Matthew Fisher</a>, <a href="https://www.cse.iitb.ac.in/~sidch/" style="text-decoration: none">Siddhartha Chaudhuri</a>, and <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>
	<br>
	Accepted to ICCV 2019
	<br>
	[<a href="https://arxiv.org/abs/1903.11228" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/czq142857/BAE-NET" style="text-decoration: none">GitHub</a>]
	<br>
	</td>
</tr>


<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/1812.02822" style="text-decoration: none">
			<img src="image/cvpr19_imnet.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>Learning Implicit Fields for Generative Shape Modeling</strong>
	<br>
	<u>Zhiqin Chen</u> and <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>
	<br>
	Accepted to CVPR 2019
	<br>
	[<a href="https://arxiv.org/abs/1812.02822" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/czq142857/IM-NET" style="text-decoration: none">GitHub</a>]
	<br>
	</td>
</tr>


<tr>
	<td colspan="1" valign="middle" >
		<a href="https://arxiv.org/abs/1803.08467" style="text-decoration: none">
			<img src="image/tip20_bsdgan.png" width="256" height="256" />
		</a>
	</td>
	<td colspan="4" valign="middle"><strong>BSD-GAN: Branched Generative Adversarial Network for Scale-Disentangled Representation Learning and Image Synthesis</strong>
	<br>
	<a href="http://www.cs.mun.ca/~yz7241/" style="text-decoration: none">Zili Yi</a>, <u>Zhiqin Chen</u>, Hao Cai, Wendong Mao, <a href="http://www.cs.mun.ca/~gong/" style="text-decoration: none">Minglun Gong</a>, and <a href="http://www.cs.sfu.ca/~haoz/" style="text-decoration: none">Hao Zhang</a>
	<br>
	Accepted to IEEE Transactions on Image Processing (TIP)
	<br>
	[<a href="https://arxiv.org/abs/1803.08467" style="text-decoration: none">ArXiv</a>] [<a href="https://github.com/duxingren14/BSD-GAN" style="text-decoration: none">GitHub</a>]
	<br>
	</td>
</tr>


<tr>
	<td colspan="3" valign="middle" >
		<br><br>
		<h2>Awards and honors</h2>
		<a href="https://cvpr2023.thecvf.com/Conferences/2023/AcceptedPapers" style="text-decoration: none">Best Paper Award Candidate</a>, CVPR 2023<br>
		<a href="https://research.google/outreach/phd-fellowship/recipients/" style="text-decoration: none">Google PhD Fellowship</a>, 2021,2022<br>
		<a href="https://blogs.nvidia.com/blog/2020/12/04/graduate-fellowships-gpu-computing-research/" style="text-decoration: none">NVIDIA Graduate Fellowship Finalist</a>, 2021<br>
		<a href="http://cvpr2020.thecvf.com/node/817" style="text-decoration: none">Best Student Paper Award</a>, CVPR 2020<br>
		Faculty of Applied Sciences Graduate Fellowship, 2018<br>
	</td>
</tr>



<tr>
	<td colspan="3" valign="middle" >
		<br><br>
		<h2>Working experience</h2>
		Adobe Internship, May - Nov, 2020<br>
		NVIDIA Internship, May - Nov, 2021<br>
		Google Student Researcher, Nov 2021 - Jul 2022<br>
	</td>
</tr>


<tr>
	<td colspan="3" valign="middle" >
		<br><br>
		<h2>Teaching Assistant</h2>
		Spring 2020 - CMPT 743 G101 practices in visual computing II
		<br>
		Spring 2019 - CMPT 743 G101 practices in visual computing II
		<br>
		Fall 2017 - CMPT 120 D100 introduction to computing science and programming I
		<br>
	</td>
</tr>


<tr>
	<td colspan="3" valign="middle" >
		<br><br>
		<h2>Reviewer</h2>
		GMOD 2018, &nbsp; PG 2019, &nbsp; CVPR 2020, &nbsp; SIGGRAPH Asia 2020, &nbsp; PG 2020, &nbsp; TOG 2020,<br>
		WACV 2021, &nbsp; ICME 2021, &nbsp; CVPR 2021, &nbsp; IJCAI 2021, &nbsp; IJCV 2021, &nbsp; TVCG 2021, &nbsp; ICCV 2021, &nbsp; 3DV 2021,<br>
		CVPR 2022, &nbsp; EG 2022, &nbsp; IJCAI-ECAI 2022, &nbsp; SIGGRAPH 2022, &nbsp; SIGGRAPH Asia 2022, &nbsp; TVCG 2022, &nbsp; TIP 2022, &nbsp;<br>
		CVPR 2023, &nbsp; TOG 2023, &nbsp; IJCAI 2023, &nbsp; SIGGRAPH 2023, &nbsp; ICCV 2023, &nbsp; SIGGRAPH Asia 2023, &nbsp; NeurIPS 2023, &nbsp;
	</td>
</tr>


<tr>
	<td>
		<br><br><br><br><br><br>
	</td>
</tr>

</table>
</div>
</body>
</html>
